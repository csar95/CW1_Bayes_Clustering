{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def pre_processing(val=True):\n",
    "    \n",
    "    data = pd.read_csv('data/x_train_gr_smpl.csv')\n",
    "    labels = pd.read_csv('data/y_train_smpl.csv')\n",
    "\n",
    "    if(val):\n",
    "        ## ---------------- Data preparation ---------------- ##\n",
    "        X_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            img = np.uint8(data.iloc[i])\n",
    "            edited = cv2.Canny(img, 10, 30)\n",
    "            edited = cv2.GaussianBlur(edited, (5, 5), 0)\n",
    "            X_train.append(edited.reshape((1,-1))[0])\n",
    "\n",
    "        data = pd.DataFrame(X_train)\n",
    "        ## -------------------------------------------------- ##\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 10 Homogeneity score: 0.4941480704250148\n",
      "Number of clusters: 11 Homogeneity score: 0.5159853723237561\n",
      "Number of clusters: 12 Homogeneity score: 0.5146366127821865\n",
      "Number of clusters: 13 Homogeneity score: 0.5278759052918507\n",
      "Number of clusters: 14 Homogeneity score: 0.5333726747258547\n",
      "Number of clusters: 15 Homogeneity score: 0.5640689586211225\n",
      "Number of clusters: 16 Homogeneity score: 0.5555233531974998\n",
      "Number of clusters: 17 Homogeneity score: 0.5837853645510892\n",
      "Number of clusters: 18 Homogeneity score: 0.5969397137445074\n",
      "Number of clusters: 19 Homogeneity score: 0.5946190526092541\n",
      "Number of clusters: 20 Homogeneity score: 0.6082159882644707\n",
      "Number of clusters: 50 Homogeneity score: 0.7032531269938882\n",
      "Number of clusters: 100 Homogeneity score: 0.7508869983980473\n"
     ]
    }
   ],
   "source": [
    "# Compare homogeneity score with different number of clusters\n",
    "\n",
    "n_clusters = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 50, 100]\n",
    "\n",
    "data, labels = pre_processing()\n",
    "labels = np.reshape(labels.values, newshape=(1, -1))\n",
    "\n",
    "for n in n_clusters:\n",
    "    estimator = KMeans(n_clusters=n, max_iter=50000, random_state=1, n_jobs=-1).fit(data)\n",
    "    print(f'Number of clusters: {n} Homogeneity score: {homogeneity_score(labels[0], estimator.labels_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the optimal number of clusters: Elbow method\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data, _ = pre_processing()\n",
    "sum_of_squared_distances = []\n",
    "n_clusters = [1, 4, 7, 10, 13, 16, 19, 30, 50, 100]\n",
    "\n",
    "for k in n_clusters:\n",
    "    estimator = KMeans(n_clusters=k).fit(data)\n",
    "    sum_of_squared_distances.append(estimator.inertia_)\n",
    "\n",
    "plt.plot(n_clusters, sum_of_squared_distances, 'bo-')\n",
    "plt.xlabel('Num. of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4526422355575307\n"
     ]
    }
   ],
   "source": [
    "# Trying different algorithm: EM algorithm\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as EM\n",
    "\n",
    "\n",
    "data, labels = pre_processing()\n",
    "\n",
    "data['label'] = labels\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data['label'] \n",
    "\n",
    "em = EM(n_components=10, max_iter=100, n_init=1).fit(X)\n",
    "proba = em.predict_proba(X)\n",
    "y_pred = em.predict(X)\n",
    "print(homogeneity_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12660, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(proba.shape)\n",
    "print(proba[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 1 6 3 9 7 7 4 6]\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.3485283947296345e-16\n"
     ]
    }
   ],
   "source": [
    "# Trying different algorithm: Mean Shift algorithm\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "\n",
    "top_10_array = set()\n",
    "\n",
    "data, _ = pre_processing()\n",
    "\n",
    "for i in range(10):\n",
    "    data = data.reindex(np.arange(data.shape[0]))\n",
    "    labels = pd.read_csv(f'data/y_train_smpl_{i}.csv')\n",
    "    data['label'] = labels\n",
    "    data = data.sample(frac=1)\n",
    "    \n",
    "    corr_label = data.drop(\"label\", axis=1).apply(lambda x: x.corr(data.label))\n",
    "    corr_label = [(index, abs(corr_val), i) for index, corr_val in enumerate(corr_label)]\n",
    "    corr_label = sorted(corr_label, key=lambda tup: tup[1], reverse=True)  # Order by correlation value\n",
    "            \n",
    "    for tup in corr_label[:10]:\n",
    "        top_10_array.add(tup[0])\n",
    "        \n",
    "data, labels = pre_processing()\n",
    "labels = np.reshape(labels.values, newshape=(1, -1))\n",
    "data_top_10 = data[data.columns[list(top_10_array)]].copy(deep=True)\n",
    "\n",
    "estimator = MeanShift().fit(data_top_10)\n",
    "print(homogeneity_score(labels[0], estimator.labels_))\n",
    "print(ciao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
